---
title: LLM Training
author: Youjin Lee
date: 2025-03-01
category: Jekyll
layout: post
mermaid: true
---


EEVE
-------------

Paper Name:<br/>
Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models[^1]

Authors:<br/>
Seungduk kim et al.

Presented:<br/>
Feb 2024

<br/>

위 논문은 영어와 한국어 텍스트 이해 능력이 뛰어난 Korean adapatation을 시킨 LLM 모델, EEVE-Korean-v1.0을 소개한다. SOLAR-10.7B, Phi-2와 같은 영어 중심 모델은 비영어권 언어를 비효율적으로 처리하기 때문에, parameter freezing(파라미터 동결)과 subword initilization(서브워드 초기화)을 통한 efficient and effective vocabulary expansion(EEVE) 방법을 제안했다. 새로운 임베딩을 위해서는 조 단위의 토큰 학습이 필요하다는 의견과 달리 2B 토큰만으로 이를 달성했다는 점에서 의미가 있다.

<div class="table-wrapper" markdown="block">

|title1|title2|title3|title4|title5|title6|title7|title8|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|1|2|3|4|5|6|7|8|
|1|2|3|4|5|6|7|8|
|1|2|3|4|5|6|7|8|
|1|2|3|4|5|6|7|8|

</div>

[^1]: [https://arxiv.org/pdf/2402.14714](https://arxiv.org/pdf/2402.14714)
